---
layout: post
title:
date: '2021-11-25'
categories: DSA
note:
mermaid: true
publish: true
---

## Introduction

Before we dive into it, please understand concept of [complexity]({{site.baseurl}}/dsa/2022/05/02/complexity.html).

Data structures describe how data can be organized, stored, and manipulated. Some common data structures include arrays, linked lists, stacks, queues, trees, graphs, and hash tables. Algorithms are procedures for solving problems such as searching for information, sorting data, processing graphs, performing calculations, and many other tasks.

* Structure
  * array, arraylist, string
  * linked list
  * stack
  * queue
  * tree
  * graph
  * hash table
  * ...
* Most common algorithms (according to ChatGPT)
  * string
    * reversing a string
    * string is a palindrome
    * longest common prefix
  * array
    * finding the maximum subarray
    * binary search
    * sorting an array
      * merge sort
      * quick sort
  * dynamic programming
    * longest increasing subsequence
    * 0/1 knapsack problem
  * Graph traversal
    * shortest path between two nodes
    * detecting cycles in a graph
  * ...
* key concepts (according to cracking the coding interview)
  * bit Manipulation
  * memory (stack vs. heap)
  * recursion
  * dynamic programming
  * big O about time and space complexity

## Why

To solve problem in a more efficient way, making no more space to improve both the time complexity and space complexity.

## How

We can decompose all the programming logics into four actions:

* create (insert)
* read (access with id)
* update (access with attributes)
* delete (delete)

| time complexity | arraylist | linkedlist | stack |
| :--- | :----: | :----: | :----: |
| C | O(1) - O(n) | O(1) |
| R | O(1) |  |
| U | O(1) |  |
| D | O(1) - O(n) |  |      

### array

* example:

```javascript
[1, 2, 3, 4]
```

* create: O(1) to O(N)
  * inserting an element at the end of an array has $$O(1)$$
  * inserting an element at the beginning of an array has $$O(N)$$ because we need to shift all the elements
* read: O(1)
  * given an index i, the read operation in an ArrayList retrieves the element at that index in constant time, regardless of the size of the ArrayList.
  * linear search has $$O(N)$$ because it needs to search the value from beginning
* update: O(1)
  * Given an index i and a new value v, the update operation in an ArrayList replaces the element at index i with the new value v in constant time, regardless of the size of the ArrayList.
* delete: O(1) to O(N)
  * in the worst case, where n is the number of elements in the ArrayList because deleting an element requires shifting all subsequent elements one position to the left to fill the gap left by the deleted element. Deleting the last element in an ArrayList has a time complexity of O(1) on average because it can be done by simply updating the size of the ArrayList

### linkedlist

* singly linked list: pointer points the next node in each node
<div class="mermaid">
graph LR
  id1((A)) --> id2((B))
  id2((B)) --> id3((C))
  id3((C)) --> id4((...))
</div>
* doubly linked list: pointer points the next and previous nodes in each node
<div class="mermaid">
graph LR
  id1((A)) --> id2((B))
  id2((B)) --> id1((A))
  id2((B)) --> id3((C))
  id3((C)) --> id2((B))
  id3((C)) --> id4((...))
  id4((...)) --> id3((C))
</div>

* coding example:

```javascript
// Define a Node class for the elements of the linked list
class Node {
  constructor(data, next = null) {
    this.data = data;
    this.next = next;
  }
}

// Define the LinkedList class
class LinkedList {
  constructor() {
    this.head = null;
    this.tail = null;
    this.length = 0;
  }

  // Add a new element to the end of the list
  add(data) {
    const node = new Node(data);
    if (!this.head) {
      this.head = node;
      this.tail = node;
    } else {
      this.tail.next = node;
      this.tail = node;
    }
    this.length++;
  }

  // Get an element at a specified index
  get(index) {
    if (index < 0 || index >= this.length) {
      return null;
    }
    let current = this.head;
    for (let i = 0; i < index; i++) {
      current = current.next;
    }
    return current.data;
  }

  // Remove an element at a specified index
  remove(index) {
    if (index < 0 || index >= this.length) {
      return null;
    }
    let current = this.head;
    if (index === 0) {
      this.head = current.next;
      if (this.length === 1) {
        this.tail = null;
      }
    } else {
      let previous = null;
      for (let i = 0; i < index; i++) {
        previous = current;
        current = current.next;
      }
      previous.next = current.next;
      if (index === this.length - 1) {
        this.tail = previous;
      }
    }
    this.length--;
    return current.data;
  }
}

// Example usage
const list = new LinkedList();
list.add('a');
list.add('b');
list.add('c');
console.log(list.get(1)); // Output: "b"
list.remove(1);
console.log(list.get(1)); // Output: "c"
```

* create: O(1)
  * adding a new element to a LinkedList involves creating a new node and updating the head pointer to point to the new node, which can be done in constant time
* read: O(n)
  * In singly-linked list, the time complexity of read is O(n) in the worst case, where n is the length of the list Unlike an array, where elements are stored contiguously in memory and can be accessed in constant time using an index, in a linked list, we have to traverse the list from the head node to the desired index, which takes linear time proportional to the size of the list.
* update: O(n)
  * In a singly-linked list, the time complexity of update (i.e., modifying an element by index) is also O(n) in the worst case, where n is the length of the list. This is because like accessing an element, we need to traverse the list from the head node to the desired index to update it. Once we have reached the node, updating it takes constant time, i.e., O(1).
* delete: O(n)
  * In a singly-linked list, the time complexity of delete (i.e., removing an element by index) is also O(n) in the worst case, where n is the length of the list. This is because we need to traverse the list from the head node to the node immediately before the one we want to delete, which takes linear time proportional to the size of the list. Once we have found the node before the one we want to delete, we can remove the target node in constant time, i.e., O(1), by updating its predecessor's next pointer to skip over the target node.

### stack

<img src="{{site.baseurl}}/assets/img/stack.png" alt="">
image source: https://www.geeksforgeeks.org/stack-data-structure/

* coding example:

```javascript
class Stack {
  constructor() {
    this.items = [];
  }

  push(element) {
    this.items.push(element);
  }

  pop() {
    if (this.items.length === 0) {
      return "Underflow";
    }
    return this.items.pop();
  }

  peek() {
    return this.items[this.items.length - 1];
  }

  isEmpty() {
    return this.items.length === 0;
  }

  size() {
    return this.items.length;
  }

  print() {
    console.log(this.items.toString());
  }
}

// Example usage
const stack = new Stack();
stack.push(10);
stack.push(20);
stack.push(30);
console.log(stack.peek()); // Output: 30
console.log(stack.pop()); // Output: 30
stack.print(); // Output: [10, 20]
```

* create: O(1)
  * simply initializing a new stack data structure with an empty array or linked list, which can be done in constant time, regardless of the size of the stack.
* read: O(1)
  * we can only access the top, so the time complexity of this operation is O(1), which is constant time complexity.
* update: O(1)
  * Again, we can only access the top, so the time complexity of this operation is O(1)
* delete:
  * Again, we can only access the top, so the time complexity of this operation is O(1)

### queue

<img src="{{site.baseurl}}/assets/img/queue.png" alt="">
image source: https://www.geeksforgeeks.org/queue-data-structure/

* code example:

```javascript
class Queue {
  constructor() {
    this.items = [];
  }

  enqueue(element) {
    this.items.push(element);
  }

  dequeue() {
    if (this.isEmpty()) {
      return "Queue is empty";
    }
    return this.items.shift();
  }

  peek() {
    if (this.isEmpty()) {
      return "Queue is empty";
    }
    return this.items[0];
  }

  isEmpty() {
    return this.items.length === 0;
  }

  size() {
    return this.items.length;
  }

  print() {
    console.log(this.items.toString());
  }
}

// Example usage
const queue = new Queue();
console.log(queue.isEmpty()); // true
queue.enqueue(1);
queue.enqueue(2);
queue.enqueue(3);
queue.print(); // [1, 2, 3]
console.log(queue.size()); // 3
console.log(queue.peek()); // 1
console.log(queue.dequeue()); // 1
console.log(queue.print()); // [2, 3]
console.log(queue.size()); // 2
```

* create: O(1)
  * the enqueue method will concatenate item on the last without elements shifting
* read: O(1)
  * reading the front element of the queue, then the time complexity of this operation is O(1)
  * accessing elements from the middle or end of a queue is not supported, which can result in a time complexity of O(n).
* update: O(n)
  * dequeuing an element from the front of the queue may require shifting all the remaining elements one position to the front of the queue, which takes O(n) time in the worst case. Then, enqueuing the modified element again requires O(1) time complexity. Therefore, the overall time complexity for updating an element in a queue is O(n).
* delete: O(1)
  * deleting an element from the front of a queue simply involves removing the first element of an array-based queue or the head node of a linked-list based queue, which can be done in constant time, regardless of the size of the queue.

### trees

* code example (binary tree)

```javascript
class TreeNode {
  constructor(val = null, left = null, right = null) {
    this.val = val;
    this.left = left;
    this.right = right;
  }
}

function createTree(data) {
  if (!data.length) {  // Base case: empty data
    return null;
  }

  const mid = Math.floor(data.length / 2);  // Find middle index of data
  const root = new TreeNode(data[mid]);  // Create root node with middle value

  // Recursively create left and right subtrees
  root.left = createTree(data.slice(0, mid));
  root.right = createTree(data.slice(mid + 1));

  return root;
}
```

* create: O(n)
  * using a recursive algorithm is O(n), where n is the number of nodes in the tree. The recursive algorithm traverses each node in the tree exactly once. Specifically, at each level of the recursion, the algorithm creates one node and recursively calls itself twice to create the left and right subtrees. Since each node is created exactly once, the total number of operations performed by the algorithm is proportional to the number of nodes in the tree, which is O(n).
  * Inserting a new node into a binary tree requires finding the correct position for the new node in the tree. In the worst case, this involves traversing the height of the tree, which has a time complexity of O(log n) for a balanced binary tree and O(n) for an unbalanced binary tree.
* read: O(n)
  * Pre-order traversal visits each node in the tree in the order root, left subtree, right subtree. The time complexity of pre-order traversal is O(n), where n is the number of nodes in the tree.
  * In-order traversal visits each node in the tree in the order left subtree, root, right subtree. The time complexity of in-order traversal is also O(n), where n is the number of nodes in the tree.
  * Post-order traversal visits each node in the tree in the order left subtree, right subtree, root. The time complexity of post-order traversal is also O(n), where n is the number of nodes in the tree.
  * Level-order traversal visits each node in the tree by level, starting at the root and moving down to each level. The time complexity of level-order traversal is also O(n), where n is the number of nodes in the tree.
* update: O(1)
  * Updating a node in a binary tree involves finding the node to be updated and then modifying its value. This can be done in O(1) time once the node has been found (O(n)).
* delete: O(log n) to O(n)
  * Deleting a node from a binary tree requires finding the node to be deleted and then rearranging the tree to maintain its properties. In the worst case, this also involves traversing the height of the tree, which has a time complexity of O(log n) for a balanced binary tree and O(n) for an unbalanced binary tree.

### graphs

* code example

```javascript
class Graph {
  constructor() {
    this.nodes = new Map();
  }

  addNode(node) {
    this.nodes.set(node, []);
  }

  addEdge(nodeA, nodeB) {
    if (!this.nodes.has(nodeA)) {
      this.addNode(nodeA);
    }
    if (!this.nodes.has(nodeB)) {
      this.addNode(nodeB);
    }
    this.nodes.get(nodeA).push(nodeB);
    this.nodes.get(nodeB).push(nodeA);
  }

  getNeighbors(node) {
    return this.nodes.get(node);
  }
}

// Create a new graph
const graph = new Graph();

// Add nodes and edges to the graph
graph.addEdge("A", "B");
graph.addEdge("B", "C");
graph.addEdge("C", "D");
graph.addEdge("D", "E");
graph.addEdge("E", "F");
graph.addEdge("F", "G");
graph.addEdge("G", "A");

// Get the neighbors of node "C"
const neighborsOfC = graph.getNeighbors("C");
console.log(neighborsOfC); // Output: ["B", "D"]
```

* time complexity (to be continued)

### tries

to be continued

### hash table

to be continued

### dynamic programming

to be continued

Arrays: Arrays are commonly used in dynamic programming to store the results of subproblems. The values in the array represent the solutions to subproblems, and the array can be indexed to quickly access the solution to a specific subproblem.

Hash tables: Hash tables can be used to store the solutions to subproblems in a way that allows for efficient lookup. Hash tables are particularly useful when the solutions to subproblems have a sparse or irregular structure.

Trees: Trees can be used to represent the dependencies between subproblems in a dynamic programming solution. The parent-child relationships between nodes in the tree correspond to the subproblem relationships, and the values stored at each node represent the solutions to the subproblems.

Graphs: Graphs can be used to represent the dependencies between subproblems in a more general way than trees. Graphs can handle cyclic dependencies between subproblems, as well as cases where multiple subproblems depend on the same subproblem.

## what

### array



### linkedlist

## reference

cracking the coding interview

[**The top data structures you should know for your next coding interview**](https://www.freecodecamp.org/news/the-top-data-structures-you-should-know-for-your-next-coding-interview-36af0831f5e3/)
